cora_v1:
  version: v1
  dataset: cora
  node_classification: True
  pretrain_epochs: 500
  finetune_epochs: 500
  finetune_interval: 50
  pretrain_lr: 0.001
  finetune_lr: 0.001
  pretrain_wd: 5e-4
  finetune_wd: 0
  pretrain_dropout: 0.1
  finetune_dropout: 0.9
  encoder_type: gcn
  encoder_layers: 2
  decoder_type: gcn
  decoder_layers: 2
  node_attr_attention: False
  node_attr_attention_dropout: 0.0
  encoder_node_attr_attention: False
  encoder_node_attr_attention_dropout: 0.0
  attr_loss_type: bce
  num_hidden: 512
  out_dim: 512
  heads: 4
  aug_e: 0
  aug_a: 0
  epsï¼š1e-10

cora_v2:
  version: v2
  dataset: cora
  node_classification: True
  pretrain_epochs: 500
  finetune_epochs: 500
  finetune_interval: 50
  pretrain_lr: 0.001
  finetune_lr: 0.001
  pretrain_wd: 0.001
  finetune_wd: 0.001
  pretrain_dropout: 0.3
  finetune_dropout: 0.9
  encoder_type: gcn
  encoder_layers: 2
  decoder_type: gcn
  decoder_layers: 2
  node_attr_attention: False
  node_attr_attention_dropout: 0.0
  encoder_node_attr_attention: False
  encoder_node_attr_attention_dropout: 0.0
  attr_loss_type: bce
  num_hidden: 512
  out_dim: 512
  heads: 4
  aug_e: 0
  aug_a: 0
  eps: 1e-10

cora_v3:
  version: v2
  dataset: cora
  node_classification: True
  pretrain_epochs: 500
  finetune_epochs: 500
  finetune_interval: 50
  pretrain_lr: 0.001
  finetune_lr: 0.001
  pretrain_wd: 0.001
  finetune_wd: 0.001
  pretrain_dropout: 0.3
  finetune_dropout: 0.9
  encoder_type: gcn
  encoder_layers: 2
  decoder_type: gcn
  decoder_layers: 2
  node_attr_attention: False
  node_attr_attention_dropout: 0.0
  encoder_node_attr_attention: False
  encoder_node_attr_attention_dropout: 0.0
  attr_loss_type: bce
  num_hidden: 512
  out_dim: 512
  heads: 4
  aug_e: 0.2
  aug_a: 0.1
  eps: 1e-10